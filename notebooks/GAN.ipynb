{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Reshape, Conv2DTranspose, Conv2D, Flatten, Dropout, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20*20*64, activation='relu', input_dim=64))\n",
    "    model.add(Reshape((20,20,64)))#20\n",
    "    model.add(Conv2DTranspose(64, (3,4), strides=(3,3), padding='same', activation='relu'))#60\n",
    "    model.add(UpSampling2D((2,2)))\n",
    "    model.add(Conv2D(3, (5,5), activation='sigmoid', padding='same'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 25600)             1664000   \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DT (None, 60, 60, 64)        49216     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2 (None, 120, 120, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 120, 120, 3)       4803      \n",
      "=================================================================\n",
      "Total params: 1,718,019\n",
      "Trainable params: 1,718,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    '''return discriminator model'''\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (4,4), strides=(2,2), activation='relu', padding='same', input_shape=(120,120,3)))\n",
    "    model.add(MaxPooling2D((2,2),padding='same'))\n",
    "    model.add(Conv2D(32, (4,4), strides=(3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2,2),padding='same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer=Adam())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 60, 60, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 10, 10, 32)        16416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 801       \n",
      "=================================================================\n",
      "Total params: 18,785\n",
      "Trainable params: 18,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_vector(n_samples):\n",
    "    '''generate vector in latent dimension'''\n",
    "    return np.random.rand(n_samples,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(generator, n_samples):\n",
    "    '''generate fake samples from random numbers'''\n",
    "    fake_input = generate_latent_vector(n_samples)\n",
    "    return generator.predict(fake_input), np.zeros((n_samples, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    mask = np.random.choice(range(dataset.shape[0]),n_samples)\n",
    "    return dataset[mask,:,:,:], np.ones((n_samples, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan(g, d):\n",
    "    d.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(g)\n",
    "    model.add(d)\n",
    "    model.compile(loss='binary_crossentropy',optimizer=Adam())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g, d, gan, dataset, n_epochs=100, n_batch=256):\n",
    "    batch_per_epoch = int(dataset.shape[0]/n_batch)\n",
    "    for i in range(n_epochs):\n",
    "        for j in range(batch_per_epoch):\n",
    "            # get real\n",
    "            x_real, y_real = generate_real_samples(dataset, int(n_batch/2))\n",
    "            # generate fake\n",
    "            x_fake, y_fake = generate_fake_samples(g, int(n_batch/2))\n",
    "\n",
    "            # create training\n",
    "            x, y = np.vstack((x_real, x_fake)), np.vstack((y_real, y_fake))\n",
    "\n",
    "            # update discriminator\n",
    "            d_loss = d.train_on_batch(x, y)\n",
    "\n",
    "            # generate fake\n",
    "            x_gan = generate_latent_vector(n_batch)\n",
    "            y_gan = np.ones((n_batch,1))\n",
    "\n",
    "            # train generator\n",
    "            gan_loss = gan.train_on_batch(x_gan, y_gan)\n",
    "\n",
    "            # summarize\n",
    "            print('>Epoch: %d, %d/%d, d loss=%.3f, gan loss=%.3f' % (i+1, j+1, batch_per_epoch, d_loss, gan_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = generator()\n",
    "d = discriminator()\n",
    "gan = gan(g, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-a62c974a6759>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "train(g, d, gan, dataset, n_epochs=1, n_batch=256)\n",
    "time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_fake_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-168041060f86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_fake_samples' is not defined"
     ]
    }
   ],
   "source": [
    "fake = generate_fake_samples(g,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('../data/fusions.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
