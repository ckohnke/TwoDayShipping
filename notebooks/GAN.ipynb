{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Reshape, Conv2DTranspose, Conv2D, Flatten, Dropout, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20*20*64, activation='relu', input_dim=64))\n",
    "    model.add(Reshape((20,20,64)))#20\n",
    "    model.add(Conv2DTranspose(64, (4,4), strides=(3,3), padding='same', activation='relu'))#60\n",
    "    model.add(Conv2DTranspose(64, (4,4), strides=(2,2), padding='same', activation='relu'))#60\n",
    "    model.add(Conv2D(3, (5,5), activation='sigmoid', padding='same'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    '''return discriminator model'''\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (4,4), strides=(2,2), activation='relu', padding='same', input_shape=(120,120,3)))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Conv2D(32, (4,4), strides=(3,3), activation='relu', padding='same'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer=Adam())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 60, 60, 32)        1568      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 60, 60, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 20, 32)        16416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 12801     \n",
      "=================================================================\n",
      "Total params: 30,785\n",
      "Trainable params: 30,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 25600)             1664000   \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 60, 60, 64)        65600     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 120, 120, 64)      65600     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 120, 120, 3)       4803      \n",
      "=================================================================\n",
      "Total params: 1,800,003\n",
      "Trainable params: 1,800,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_vector(n_samples):\n",
    "    '''generate vector in latent dimension'''\n",
    "    return np.random.rand(n_samples,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(generator, n_samples):\n",
    "    '''generate fake samples from random numbers'''\n",
    "    fake_input = generate_latent_vector(n_samples)\n",
    "    return generator.predict(fake_input), np.zeros((n_samples, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    mask = np.random.choice(range(dataset.shape[0]),n_samples)\n",
    "    return dataset[mask,:,:,:], np.ones((n_samples, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan(g, d):\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(g)\n",
    "    model.add(d)\n",
    "    model.compile(loss='binary_crossentropy',optimizer=Adam())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g, d, gan, dataset, n_epochs=100, n_batch=256):\n",
    "    batch_per_epoch = int(dataset.shape[0]/n_batch)\n",
    "    for i in range(n_epochs):\n",
    "        for j in range(batch_per_epoch):\n",
    "            # get real\n",
    "            x_real, y_real = generate_real_samples(dataset, int(n_batch/2))\n",
    "            # generate fake\n",
    "            x_fake, y_fake = generate_fake_samples(g, int(n_batch/2))\n",
    "\n",
    "            # create training\n",
    "            x, y = np.vstack((x_real, x_fake)), np.vstack((y_real, y_fake))\n",
    "\n",
    "            # update discriminator\n",
    "            d_loss = d.train_on_batch(x,y)\n",
    "\n",
    "            # generate fake\n",
    "            x_gan = generate_latent_vector(n_batch)\n",
    "            y_gan = np.ones((n_batch,1))\n",
    "\n",
    "            # train generator\n",
    "            gan_loss = gan.train_on_batch(x_gan, y_gan)\n",
    "\n",
    "            # summarize\n",
    "            print('>Epoch: %d, %d/%d, d loss=%.3f, gan loss=%.3f' % (i+1, j+1, batch_per_epoch, d_loss, gan_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "g = generator()\n",
    "d = discriminator()\n",
    "gan = gan(g, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('../data/fusions.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22349, 120, 120, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "train(g, d, gan, dataset, n_epochs=1, n_batch=256)\n",
    "time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
